{"ast":null,"code":"import Anthropic from \"@anthropic-ai/sdk\";\nimport { HfInference } from '@huggingface/inference';\nconst SYSTEM_PROMPT = `\nYou are an assistant that receives a list of ingredients that a user has and suggests a recipe they could make with some or all of those ingredients. You don't need to use every ingredient they mention in your recipe. The recipe can include additional ingredients they didn't mention, but try not to include too many extra ingredients. Format your response in markdown to make it easier to render to a web page\n`;\nconst anthropic = new Anthropic({\n  // for ANTHROPIC_API_KEY\n  // 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\n  apiKey: process.env.ANTHROPIC_API_KEY,\n  dangerouslyAllowBrowser: true\n});\nexport async function getRecipeFromChefClaude(ingredientsArr) {\n  const ingredientsString = ingredientsArr.join(\", \");\n  const msg = await anthropic.messages.create({\n    model: \"claude-3-haiku-20240307\",\n    max_tokens: 1024,\n    system: SYSTEM_PROMPT,\n    messages: [{\n      role: \"user\",\n      content: `I have ${ingredientsString}. Please give me a recipe you'd recommend I make!`\n    }]\n  });\n  return msg.content[0].text;\n}\n\n// Make sure you set an environment variable in Scrimba \n// for HF_ACCESS_TOKEN\n//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\nconst hf = new HfInference(process.env.HF_ACCESS_TOKEN);\nexport async function getRecipeFromMistral(ingredientsArr) {\n  const ingredientsString = ingredientsArr.join(\", \");\n  try {\n    const response = await hf.chatCompletion({\n      model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n      messages: [{\n        role: \"system\",\n        content: SYSTEM_PROMPT\n      }, {\n        role: \"user\",\n        content: `I have ${ingredientsString}. Please give me a recipe you'd recommend I make!`\n      }],\n      max_tokens: 1024\n    });\n    return response.choices[0].message.content;\n  } catch (err) {\n    console.error(err.message);\n  }\n}","map":{"version":3,"names":["Anthropic","HfInference","SYSTEM_PROMPT","anthropic","apiKey","process","env","ANTHROPIC_API_KEY","dangerouslyAllowBrowser","getRecipeFromChefClaude","ingredientsArr","ingredientsString","join","msg","messages","create","model","max_tokens","system","role","content","text","hf","HF_ACCESS_TOKEN","getRecipeFromMistral","response","chatCompletion","choices","message","err","console","error"],"sources":["D:/Woooork/Required 5 projects/Chef cloud app/src/ai.js"],"sourcesContent":["import Anthropic from \"@anthropic-ai/sdk\"\r\nimport { HfInference } from '@huggingface/inference'\r\n\r\nconst SYSTEM_PROMPT = `\r\nYou are an assistant that receives a list of ingredients that a user has and suggests a recipe they could make with some or all of those ingredients. You don't need to use every ingredient they mention in your recipe. The recipe can include additional ingredients they didn't mention, but try not to include too many extra ingredients. Format your response in markdown to make it easier to render to a web page\r\n`\r\n\r\nconst anthropic = new Anthropic({\r\n    // for ANTHROPIC_API_KEY\r\n    // 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\r\n    apiKey: process.env.ANTHROPIC_API_KEY,\r\n    dangerouslyAllowBrowser: true,\r\n})\r\n\r\nexport async function getRecipeFromChefClaude(ingredientsArr) {\r\n    const ingredientsString = ingredientsArr.join(\", \")\r\n\r\n    const msg = await anthropic.messages.create({\r\n        model: \"claude-3-haiku-20240307\",\r\n        max_tokens: 1024,\r\n        system: SYSTEM_PROMPT,\r\n        messages: [\r\n            { role: \"user\", content: `I have ${ingredientsString}. Please give me a recipe you'd recommend I make!` },\r\n        ],\r\n    });\r\n    return msg.content[0].text\r\n}\r\n\r\n// Make sure you set an environment variable in Scrimba \r\n// for HF_ACCESS_TOKEN\r\n//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\r\nconst hf = new HfInference(process.env.HF_ACCESS_TOKEN)\r\n\r\nexport async function getRecipeFromMistral(ingredientsArr) {\r\n    const ingredientsString = ingredientsArr.join(\", \")\r\n    try {\r\n        const response = await hf.chatCompletion({\r\n            model: \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\r\n            messages: [\r\n                { role: \"system\", content: SYSTEM_PROMPT },\r\n                { role: \"user\", content: `I have ${ingredientsString}. Please give me a recipe you'd recommend I make!` },\r\n            ],\r\n            max_tokens: 1024,\r\n        })\r\n        return response.choices[0].message.content\r\n    } catch (err) {\r\n        console.error(err.message)\r\n    }\r\n}"],"mappings":"AAAA,OAAOA,SAAS,MAAM,mBAAmB;AACzC,SAASC,WAAW,QAAQ,wBAAwB;AAEpD,MAAMC,aAAa,GAAG;AACtB;AACA,CAAC;AAED,MAAMC,SAAS,GAAG,IAAIH,SAAS,CAAC;EAC5B;EACA;EACAI,MAAM,EAAEC,OAAO,CAACC,GAAG,CAACC,iBAAiB;EACrCC,uBAAuB,EAAE;AAC7B,CAAC,CAAC;AAEF,OAAO,eAAeC,uBAAuBA,CAACC,cAAc,EAAE;EAC1D,MAAMC,iBAAiB,GAAGD,cAAc,CAACE,IAAI,CAAC,IAAI,CAAC;EAEnD,MAAMC,GAAG,GAAG,MAAMV,SAAS,CAACW,QAAQ,CAACC,MAAM,CAAC;IACxCC,KAAK,EAAE,yBAAyB;IAChCC,UAAU,EAAE,IAAI;IAChBC,MAAM,EAAEhB,aAAa;IACrBY,QAAQ,EAAE,CACN;MAAEK,IAAI,EAAE,MAAM;MAAEC,OAAO,EAAE,UAAUT,iBAAiB;IAAoD,CAAC;EAEjH,CAAC,CAAC;EACF,OAAOE,GAAG,CAACO,OAAO,CAAC,CAAC,CAAC,CAACC,IAAI;AAC9B;;AAEA;AACA;AACA;AACA,MAAMC,EAAE,GAAG,IAAIrB,WAAW,CAACI,OAAO,CAACC,GAAG,CAACiB,eAAe,CAAC;AAEvD,OAAO,eAAeC,oBAAoBA,CAACd,cAAc,EAAE;EACvD,MAAMC,iBAAiB,GAAGD,cAAc,CAACE,IAAI,CAAC,IAAI,CAAC;EACnD,IAAI;IACA,MAAMa,QAAQ,GAAG,MAAMH,EAAE,CAACI,cAAc,CAAC;MACrCV,KAAK,EAAE,sCAAsC;MAC7CF,QAAQ,EAAE,CACN;QAAEK,IAAI,EAAE,QAAQ;QAAEC,OAAO,EAAElB;MAAc,CAAC,EAC1C;QAAEiB,IAAI,EAAE,MAAM;QAAEC,OAAO,EAAE,UAAUT,iBAAiB;MAAoD,CAAC,CAC5G;MACDM,UAAU,EAAE;IAChB,CAAC,CAAC;IACF,OAAOQ,QAAQ,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACR,OAAO;EAC9C,CAAC,CAAC,OAAOS,GAAG,EAAE;IACVC,OAAO,CAACC,KAAK,CAACF,GAAG,CAACD,OAAO,CAAC;EAC9B;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}